import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
qq
import cv2
import time
from ultralytics import YOLO

# Import module h·ªó tr·ª£
from utils.draw_utils import draw_text_pil
from utils.video_utils import setup_window, compute_fps
from rep_counter import count_squat, count_pushup
from form_rules import evaluate_squat, evaluate_pushup

# -----------------------------
# ‚öôÔ∏è C·∫•u h√¨nh
# -----------------------------
EXERCISE =  "squat" # ho·∫∑c "squat"
VIDEO_PATH = "data/raw/squat_ok_01.mp4"  # ho·∫∑c 0 n·∫øu d√πng webcam
FONT_PATH = os.path.join(os.path.dirname(__file__), "..", "fonts", "Roboto.ttf")

# -----------------------------
# üöÄ Kh·ªüi t·∫°o model
# -----------------------------
model = YOLO("yolo11n-pose.pt")
cap = cv2.VideoCapture(VIDEO_PATH)

if not cap.isOpened():
    print("‚ùå Kh√¥ng th·ªÉ m·ªü video ho·∫∑c webcam:", VIDEO_PATH)
    exit()

state = {"stage": "up", "counter": 0}
prev_time = time.time()
frame_idx = 0
print("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu. Nh·∫•n 'q' ƒë·ªÉ tho√°t.")

exercise_registry = {
    "squat": {
        "counter_func": count_squat,
        "form_func": evaluate_squat,
        "state": {"stage": "up", "counter": 0, "prev_angle": 160, "direction": "up"},
    },
    "pushup": {
        "counter_func": count_pushup,
        "form_func": evaluate_pushup,
        "state": {"stage": "up", "counter": 0, "prev_angle": 160, "direction": "up"},
    },
    # Th√™m b√†i t·∫≠p m·ªõi ·ªü ƒë√¢y:
    # "lunges": {"counter_func": count_lunges, "form_func": evaluate_lunges, "state": {...}}
}

if EXERCISE not in exercise_registry:
    raise ValueError(f"‚ùå B√†i t·∫≠p '{EXERCISE}' ch∆∞a ƒë∆∞·ª£c ƒëƒÉng k√Ω trong exercise_registry!")

counter_func = exercise_registry[EXERCISE]["counter_func"]
form_func = exercise_registry[EXERCISE]["form_func"]
state = exercise_registry[EXERCISE]["state"]

# -----------------------------
# üîÅ V√≤ng l·∫∑p ch√≠nh
# -----------------------------
while True:
    ret, frame = cap.read()
    if not ret:
        print("üé¨ H·∫øt video ho·∫∑c l·ªói ƒë·ªçc frame.")
        break

    results = model(frame, verbose=False)
    res = results[0]
    annotated = res.plot()

    counter = 0
    stage = "up"
    angle = 0
    feedback = "..."

    # N·∫øu c√≥ keypoints ‚Üí x·ª≠ l√Ω
    if res.keypoints is not None and len(res.keypoints.xy) > 0:
        kps = res.keypoints.xy[0].tolist()

        # G·ªçi h√†m ƒë·∫øm v√† ƒë√°nh gi√° form t∆∞∆°ng ·ª©ng b√†i t·∫≠p
        counter, stage, angle = counter_func(kps, state)
        form_score, feedback = form_func(kps, annotated, stage, counter)

    # FPS
    fps, prev_time = compute_fps(prev_time)

    # -----------------------------
    # üñºÔ∏è Overlay text
    # -----------------------------
    form_color = (0, 255, 0) if "t·ªët" in feedback or "chu·∫©n" in feedback else (255, 255, 0) if "c√≥ th·ªÉ" in feedback else (255, 80, 80)
    lines = [
        (f"S·ªë l·∫ßn: {counter}", (255, 215, 0)),
        (f"Tr·∫°ng th√°i: {stage}", (255, 255, 255)),
        (f"G√≥c: {int(angle)}¬∞", (144, 238, 144)),
        (f"ƒê√°nh gi√°: {feedback}", form_color),
        (f"FPS: {fps:.1f}", (200, 200, 200)),
    ]

    annotated = draw_text_pil(annotated, lines, font_path=FONT_PATH, font_scale=26, pos=(20, 20))

    # -----------------------------
    # üñ•Ô∏è Hi·ªÉn th·ªã video auto-scale
    # -----------------------------
    if frame_idx == 0:
        setup_window("AI Fitness Tracker", annotated, max_height=720)

    cv2.imshow("AI Fitness Tracker", annotated)
    frame_idx += 1

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
