import os
import cv2
import time
import torch
from ultralytics import YOLO

# -----------------------------
# üì¶ Import module h·ªó tr·ª£
# -----------------------------
from utils.draw_utils import draw_text_pil
from utils.video_utils import setup_window, compute_fps
from rep_counter import (
    count_squat, count_pushup, count_plank, count_situp
)
from form_rules import (
    evaluate_squat, evaluate_pushup, evaluate_plank, evaluate_situp
)

import voice_player

# -----------------------------
# ‚öôÔ∏è C·∫•u h√¨nh
# -----------------------------
EXERCISE =  "plank" # ho·∫∑c "squat"
VIDEO_REL = os.path.join("data", "raw", "plank_ok_01.mp4")

# file data/ n·∫±m b√™n trong src/, kh√¥ng ph·∫£i ·ªü project root -> kh√¥ng c·∫ßn ".."
VIDEO_PATH = os.path.normpath(os.path.join(os.path.dirname(__file__), VIDEO_REL))

# N·∫øu kh√¥ng t√¨m th·∫•y file th√¨ th√¥ng b√°o r√µ r√†ng v√† fallback sang webcam (0)
if not os.path.exists(VIDEO_PATH):
    print(f"‚ùå Video kh√¥ng t√¨m th·∫•y t·∫°i: {VIDEO_PATH}")
    print("‚ûú ƒê·∫∑t file v√†o data/raw/ ho·∫∑c ƒë·ªïi VIDEO_PATH. T·ª± ƒë·ªông chuy·ªÉn sang webcam (0).")
    VIDEO_PATH = 0

print(f"‚ñ∂Ô∏è S·ª≠ d·ª•ng video/webcam: {VIDEO_PATH}")

FONT_PATH = os.path.join(os.path.dirname(__file__), "..", "fonts", "Roboto.ttf")

# Add/modify these configurations at the top
BATCH_SIZE = 1
IMG_SIZE = 640  # or 480 for faster processing
DRAW_EVERY_N_FRAMES = 3  # Increase to 3 or 4 for higher FPS

# Th√™m c·∫•u h√¨nh sau ph·∫ßn CONFIG
CONF_THRESHOLD = 0.5     # L·ªçc b·ªõt detection c√≥ ƒë·ªô tin c·∫≠y th·∫•p

# -----------------------------
# üöÄ Kh·ªüi t·∫°o model (v·ªõi GPU n·∫øu c√≥)
# -----------------------------
device = "cuda:0" if torch.cuda.is_available() else "cpu"
print(f"‚ñ∂Ô∏è Device: {device}")

# Debug CUDA status
print("\n=== üîç GPU/CUDA Status ===")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"Current device: {torch.cuda.current_device()}")
    print(f"Device name: {torch.cuda.get_device_name()}")
    print(f"Device memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
else:
    print("‚ö†Ô∏è CUDA kh√¥ng kh·∫£ d·ª•ng - model ƒëang ch·∫°y tr√™n CPU")
print("=====================\n")

# T·ªëi ∆∞u th√™m cho CUDA
if device.startswith("cuda"):
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

# Modify model initialization
model = YOLO("yolo11n-pose.pt")
model.conf = CONF_THRESHOLD
model.to(device)

cap = cv2.VideoCapture(VIDEO_PATH)

if not cap.isOpened():
    print("‚ùå Kh√¥ng th·ªÉ m·ªü video ho·∫∑c webcam:", VIDEO_PATH)
    exit()
print("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu. Nh·∫•n 'q' ƒë·ªÉ tho√°t.")

# -----------------------------
# üß© ƒêƒÉng k√Ω b√†i t·∫≠p
# -----------------------------
exercise_registry = {
    "squat": {
        "counter_func": count_squat,
        "form_func": evaluate_squat,
        "state": {"stage": "up", "counter": 0, "prev_angle": 160, "direction": "up"},
    },
    "pushup": {
        "counter_func": count_pushup,
        "form_func": evaluate_pushup,
        "state": {"stage": "up", "counter": 0, "prev_angle": 160, "direction": "up"},
    },
    "plank": {
        "counter_func": count_plank,
        "form_func": evaluate_plank,
        "state": {"good_time": 0, "bad_time": 0, "is_good": False},
    },
    "situp": {
        "counter_func": count_situp,
        "form_func": evaluate_situp,
        "state": {"stage": "down", "counter": 0, "prev_angle": 140, "direction": "down"},
    },
    # Th√™m b√†i t·∫≠p m·ªõi ·ªü ƒë√¢y:
    # "situp": {"counter_func": count_situp,
    #            "form_func": evaluate_situp,
    #            "state": {...}},
}

if EXERCISE not in exercise_registry:
    raise ValueError(f"‚ùå B√†i t·∫≠p '{EXERCISE}' ch∆∞a ƒë∆∞·ª£c ƒëƒÉng k√Ω trong exercise_registry!")

counter_func = exercise_registry[EXERCISE]["counter_func"]
form_func = exercise_registry[EXERCISE]["form_func"]
state = exercise_registry[EXERCISE]["state"]


# --- Voice player init ---
VOICES_DIR = r"C:\Users\Admin\Downloads\AI-Fitness-Tracker\src\data\voices"


# --- Voice player init (periodic-only) ---
VOICES_DIR = r"C:\Users\Admin\Downloads\AI-Fitness-Tracker\src\data\voices"

# ph√°t welcome.mp3 ‚Üí ƒë·ª£i 2s ‚Üí l·∫ßn ƒë·∫ßu theo tone l√† 5s, sau ƒë√≥ gi·ªØ nguy√™n tone th√¨ 4s
voice_player.init(VOICES_DIR, base_interval_first=6.0, base_interval_same=5.0)
# ------------------------------------------------



# -----------------------------
# üîÅ V√≤ng l·∫∑p ch√≠nh
# -----------------------------
prev_time = time.time()
frame_idx = 0

while True:

    ret, frame = cap.read()
    if not ret:
        print("üé¨ H·∫øt video ho·∫∑c l·ªói ƒë·ªçc frame.")
        break
    frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))

    # Use model.predict instead of direct call for better GPU utilization
    results = model.predict(frame, 
                       verbose=False,
                       conf=CONF_THRESHOLD,
                       device=device,
                       batch=BATCH_SIZE)
    res = results[0]
    
    # Ch·ªâ v·∫Ω annotation m·ªói N frame
    if frame_idx % DRAW_EVERY_N_FRAMES == 0:
        annotated = res.plot()
    else:
        annotated = frame.copy()

    counter = 0
    stage = "up"
    angle = 0
    feedback = "..."

    # N·∫øu c√≥ keypoints ‚Üí x·ª≠ l√Ω
    if res.keypoints is not None and len(res.keypoints.xy) > 0:
        kps = res.keypoints.xy[0].tolist()

        # G·ªçi h√†m ƒë·∫øm v√† ƒë√°nh gi√° form t∆∞∆°ng ·ª©ng b√†i t·∫≠p
        counter, stage, angle = counter_func(kps, state)
        form_score, feedback, tone = form_func(kps, annotated, stage, counter)

        # C·∫≠p nh·∫≠t voice player v·ªõi tone hi·ªán t·∫°i
        # tone ƒë∆∞·ª£c thi·∫øt k·∫ø b·ªüi feedback_utils: "positive"|"neutral"|"negative"
        # voice_player s·∫Ω t√¨m file t∆∞∆°ng ·ª©ng trong VOICES_DIR (explicit mapping)
        voice_player.set_tone(tone)

    # -----------------------------
    # üßÆ T√≠nh FPS
    # -----------------------------
    fps, prev_time = compute_fps(prev_time)

    # -----------------------------
    # üñºÔ∏è Overlay text
    # -----------------------------
    form_score, feedback, tone = form_func(kps, annotated, stage, counter)

    form_color = {
        "positive": (0, 255, 0),
        "neutral": (255, 255, 0),
        "negative": (255, 80, 80)
    }.get(tone, (200, 200, 200))

    if EXERCISE == "plank":
        lines = [
            (f"Th·ªùi gian gi·ªØ: {counter:.1f}s", (255, 215, 0)),
            (f"T∆∞ th·∫ø: {'Chu·∫©n' if state.get('is_good') else 'Ch∆∞a ƒë√∫ng'}", (255, 255, 255)),
            (f"G√≥c: {int(angle)}¬∞", (144, 238, 144)),
            (f"ƒê√°nh gi√°: {feedback}", form_color),
            (f"FPS: {fps:.1f}", (200, 200, 200)),
        ]
    else:
        lines = [
            (f"S·ªë l·∫ßn: {counter}", (255, 215, 0)),
            (f"Tr·∫°ng th√°i: {stage}", (255, 255, 255)),
            (f"G√≥c: {int(angle)}¬∞", (144, 238, 144)),
            (f"ƒê√°nh gi√°: {feedback}", form_color),
            (f"FPS: {fps:.1f}", (200, 200, 200)),
        ]

    annotated = draw_text_pil(annotated, lines, font_path=FONT_PATH, font_scale=26, pos=(20, 20))

    # -----------------------------
    # üñ•Ô∏è Hi·ªÉn th·ªã video auto-scale
    # -----------------------------
    if frame_idx == 0:
        setup_window("AI Fitness Tracker", annotated, max_height=720)

    cv2.imshow("AI Fitness Tracker", annotated)
    frame_idx += 1

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# D·ª´ng voice player an to√†n
voice_player.stop()
